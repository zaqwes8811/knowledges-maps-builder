NLP problems:
  ступеньки 1, 2, 3 можно считать одним равномерным распределением

  пик составляет процентов 10 - а хвост утягивает большой объем плотности вероятности - оочень большой
  так что эквалайзер необъодим даже в начале

  много хорошо известных слов - но тестовые данные были субтитрами, так что не удивительно, но выходит нужен
  глобальный фильтр.

  отдельный слова порой не имеют значения - важны, и важнее сочетания - целых предл. может быть многовато

Solutions may be:
  фильтрация распределения - растягиваем и сглаживаем

Impl:
  на тестовой машние очень все медленно
на gae с пры страниц съедается почти все write операции! чтение тоже много, и его можно закешировать, но вот запись, это плохо и это для одного пользователя

Solutions may be:
  кеширование запросов к базе данных
