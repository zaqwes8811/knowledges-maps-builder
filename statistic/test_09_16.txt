NLP problems:
  ступеньки 1, 2, 3 можно считать одним равномерным распределением

  пик составляет процентов 10 - а хвост утягивает большой объем плотности вероятности - оочень большой
  так что эквалайзер необъодим даже в начале

  много хорошо известных слов - но тестовые данные были субтитрами, так что не удивительно, но выходит нужен
  глобальный фильтр.

  отдельный слова порой не имеют значения - важны, и важнее сочетания - целых предл. может быть многовато

Solutions may be:
  фильтрация распределения - растягиваем и сглаживаем

Impl:
  на тестовой машние очень все медленно
на gae с пры страниц съедается почти все write операции! чтение тоже много, и его можно закешировать, но вот запись, это плохо и это для одного пользователя. две 20 мин субтитры - 16% wr - это стирание и запись, ну пусть по 8 процентов, но это все равно много.
Возможно придется хранить большие объемы - сырой текст, а потом обрабатывать при запросах.

Отдельные слова и предложения в gae хранить глупо - ресурсы закончаться мгновенно.

Solutions may be:
  кеширование запросов к базе данных
